# -*- coding: utf-8 -*-
"""digit_recogniser.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SVwi6NmEaiIj9Q_ty5cPtPtbbB3wCV45
"""

import tensorflow.keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPool2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dropout
import numpy as np
import pandas as pd
import math
import matplotlib.pyplot as plt
train_data=pd.read_csv('train.csv')
test_data=pd.read_csv('test.csv')
train_data_x=pd.DataFrame(train_data.values[:, 1:])
train_data_y=(train_data.values[:, 0])

n_cols=784
num_layers=1
my_learning_rate=0.4
layer_depth=[50]
iters=20
batch=100

"""converting_data_to_desired_format::"""

def convert(arr,rows,column):
  col=arr.columns
  t=arr[col[0]].size
  df=np.zeros((t,rows,column,1))
  for i in range(t):
    data=arr.iloc[i]
    for j in range(rows):
      for k in range(column):
        df[i][j][k]=[data[column*j+k]]
  return df
new_train_data=convert(train_data_x,28,28)
new_test_data=convert(test_data,28,28)
print(new_test_data.shape)

def train_val_split(arr1,arr2,train_size):
  total=arr2.size
  i=int(total*train_size)
  x_train=arr1[0:i]
  x_val=arr1[i:total]
  y_train=arr2[0:i]
  y_val=arr2[i:total]
  return (x_train,x_val,y_train,y_val)



x_train, x_val, y_train, y_val = train_val_split(new_train_data, train_data_y, train_size=0.8)
x_train=x_train.astype('float32')/255
x_val=x_val.astype('float32')/255
new_test_data=new_test_data.astype('float32')/255

in_shape = x_train.shape[1:]
print(new_test_data[15].shape)

model=Sequential()
model.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',input_shape=(28,28,1)))
model.add(MaxPool2D(pool_size=(3,3),padding='valid'))
model.add(Flatten())
model.add(Dense(50,activation='relu',kernel_initializer='he_uniform'))
model.add(Dense(50,activation='relu',kernel_initializer='he_uniform'))
model.add(Dense(10,activation='softmax'))
opt=tensorflow.keras.optimizers.SGD(learning_rate=my_learning_rate)
model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics='accuracy')
history1=model.fit(x_train,y_train,epochs=iters,batch_size=batch,verbose=0)
loss,acc=model.evaluate(x_val,y_val,verbose=0)
print('loss_val ,acc_val :',"(",loss," ",acc*100,"%)")

global calls_made=0

'''
written by sai teja varanasi
'''

def ack(m,n):
   calls_made= calls_made+1
   if(m<0 or n<0):
      raise ValueError
   if(m==0):
      return n+1
   if(n==0):
      return ack(m-1,1)
   return ack(m-1,ack(m,n-1))

m=int(input('enter num_one(m):'))
n=int(input('enter num_two(n):'))
print(ack(m,n)," num_of_calls_made: ",calls_made)



"""this is to print final data in a sample.csv"""

index=[int(i) for i in range(iters)]
plt.xlabel('iters')
plt.ylabel('train loss')
plt.plot(index,history1.history['loss'],'bs')
plt.show()

model.save('trail1.h5')

import csv

row1=['ImageId','Label']
row=[]
for i in range(new_test_data.shape[0]):
  pre=model.predict(np.asarray([new_test_data[i]]))
  row.append([i+1,np.argmax(pre)])
with open('final.csv', 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(row1)
    writer.writerows(row)